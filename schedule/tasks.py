from __future__ import absolute_import, unicode_literals

import gc
import logging
import os
import subprocess
import time
import traceback
from datetime import datetime
from multiprocessing.dummy import Pool as ThreadPool
from typing import List

import requests
import toml
from celery.app import shared_task
from django.core.cache import cache
from django.db.models import Q
from lxml import etree

from auxiliary.base import MessageTemplate, DownloaderCategory
from auxiliary.celery import BaseTask
from download.models import Downloader
from my_site.models import MySite, TorrentInfo
from spider.views import PtSpider, toolbox
from toolbox.schema import CommonResponse
from website.models import WebSite

# å¼•å…¥æ—¥å¿—
logger = logging.getLogger('ptools')
# å¼•å…¥çº¿ç¨‹æ± 
pool = ThreadPool(8)
pt_spider = PtSpider()


# @boost('do_sign_in', broker_kind=BrokerEnum.REDIS_STREAM)
@shared_task(bind=True, base=BaseTask)
def auto_sign_in(self, *site_list: List[int]):
    """æ‰§è¡Œç­¾åˆ°"""
    start = time.time()
    logger.info('å¼€å§‹æ‰§è¡Œç­¾åˆ°ä»»åŠ¡')
    toolbox.send_text(title='é€šçŸ¥ï¼šæ­£åœ¨ç­¾åˆ°', message=f'å¼€å§‹æ‰§è¡Œç­¾åˆ°ä»»åŠ¡ï¼Œå½“å‰æ—¶é—´ï¼š{datetime.fromtimestamp(start)}')
    logger.info('ç­›é€‰éœ€è¦ç­¾åˆ°çš„ç«™ç‚¹')
    message_list = []
    queryset = [
        my_site for my_site in MySite.objects.filter(sign_in=True, id__in=site_list)
        if my_site.cookie and WebSite.objects.get(id=my_site.site).sign_in and
           my_site.signin_set.filter(created_at__date__gte=datetime.today(), sign_in_today=True).count() == 0 and
           (datetime.now().hour >= 9 or WebSite.objects.get(id=my_site.site).url not in ['https://u2.dmhy.org/'])
    ]
    message = 'ç«™ç‚¹ï¼š`U2` æ—©ä¸Šä¹ç‚¹ä¹‹å‰ä¸æ‰§è¡Œç­¾åˆ°ä»»åŠ¡å“¦ï¼ \n\n'
    logger.debug(message)
    message_list.append(message)
    if len(queryset) <= 0:
        message_list = ['å·²å…¨éƒ¨ç­¾åˆ°æˆ–æ— éœ€ç­¾åˆ°ï¼ \n\n']
        logger.info(message_list)
        # toolbox.send_text(title='é€šçŸ¥ï¼šè‡ªåŠ¨ç­¾åˆ°', message='\n'.join(message_list))
        return message_list
    results = pool.map(pt_spider.sign_in, queryset)
    logger.info('æ‰§è¡Œç­¾åˆ°ä»»åŠ¡')
    success_message = []
    failed_message = []
    for my_site, result in zip(queryset, results):
        logger.debug(f'è‡ªåŠ¨ç­¾åˆ°ï¼š{my_site}, {result}')
        if result.code == 0:
            msg = f'âœ… {my_site.nickname} ç­¾åˆ°æˆåŠŸï¼{result.msg} \n\n'
            logger.debug(msg)
            success_message.append(msg)
        else:
            message = f'ğŸ†˜ {my_site.nickname}ç­¾åˆ°å¤±è´¥ï¼š{result.msg} \n\n'
            failed_message.append(message)
            logger.error(message)
        # message_list.append(f'{my_site.nickname}: {result.msg}')
    end = time.time()
    message = f'å½“å‰æ—¶é—´ï¼š{datetime.fromtimestamp(end)},' \
              f'æœ¬æ¬¡ç­¾åˆ°ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼Œå…±æœ‰{len(queryset)}ç«™ç‚¹éœ€è¦ç­¾åˆ°ï¼ŒæˆåŠŸç­¾åˆ°{len(success_message)}ä¸ªç«™ç‚¹ï¼Œ' \
              f'å¤±è´¥{len(failed_message)}ä¸ªç«™ç‚¹ï¼Œè€—è´¹æ—¶é—´ï¼š{round(end - start, 2)} \n'
    message_list.append(message)
    message_list.extend(failed_message)
    message_list.append('*' * 20)
    # message_list.extend(success_message)
    logger.info(message)
    logger.debug(len(message_list))
    toolbox.send_text(title='é€šçŸ¥ï¼šè‡ªåŠ¨ç­¾åˆ°', message='\n'.join(message_list))
    toolbox.send_text(title='é€šçŸ¥ï¼šç­¾åˆ°æˆåŠŸ', message='\n'.join(success_message))
    # é‡Šæ”¾å†…å­˜
    gc.collect()
    return message_list


@shared_task(bind=True, base=BaseTask)
def auto_get_status(self, *site_list: List[int]):
    """
    æ›´æ–°ä¸ªäººæ•°æ®
    """
    start = time.time()
    message_list = ['# æ›´æ–°ä¸ªäººæ•°æ®  \n\n']
    failed_message = []
    success_message = []
    websites = WebSite.objects.all()
    # queryset = MySite.objects.filter(
    #     get_info=True
    # ) if len(site_list) == 0 else MySite.objects.filter(get_info=True, id__in=site_list)
    queryset = [my_site for my_site in MySite.objects.filter(get_info=True, id__in=site_list) if
                websites.get(id=my_site.site).get_info]
    results = pool.map(pt_spider.send_status_request, queryset)
    message_template = MessageTemplate.status_message_template
    for my_site, result in zip(queryset, results):
        if result.code == 0:
            # res = pt_spider.parse_status_html(my_site, result.data)
            logger.info('è‡ªåŠ¨æ›´æ–°ä¸ªäººæ•°æ®: {}, {}'.format(my_site.nickname, result))
            # if res.code == 0:
            status = result.data
            message = message_template.format(
                my_site.nickname,
                status.my_level,
                status.my_bonus,
                status.bonus_hour,
                status.my_score,
                status.ratio,
                toolbox.FileSizeConvert.parse_2_file_size(status.seed_volume),
                toolbox.FileSizeConvert.parse_2_file_size(status.uploaded),
                toolbox.FileSizeConvert.parse_2_file_size(status.downloaded),
                status.seed,
                status.leech,
                status.invitation,
                status.my_hr,
            )
            logger.info(message)
            # toolbox.send_text(title='é€šçŸ¥ï¼šä¸ªäººæ•°æ®æ›´æ–°', message=my_site.nickname + ' ä¿¡æ¯æ›´æ–°æˆåŠŸï¼' + message)
            success_message.append(f'âœ… {my_site.nickname} ä¿¡æ¯æ›´æ–°æˆåŠŸï¼{message}\n\n')
        else:
            print(result)
            message = f'ğŸ†˜ {my_site.nickname} ä¿¡æ¯æ›´æ–°å¤±è´¥ï¼åŸå› ï¼š{result.msg}'
            logger.warning(message)
            failed_message.append(f'{message} \n\n')
            # toolbox.send_text(title='é€šçŸ¥ï¼šä¸ªäººæ•°æ®æ›´æ–°', message=f'{my_site.nickname} ä¿¡æ¯æ›´æ–°å¤±è´¥ï¼åŸå› ï¼š{message}')
    # å‘é€ä»Šæ—¥æ•°æ®
    total_upload, total_download, increase_info_list = toolbox.today_data()
    increase_list = []
    for increase_info in increase_info_list:
        info = f'\n\n- â™»ï¸ ç«™ç‚¹ï¼š{increase_info.get("name")}'
        if increase_info.get("uploaded") > 0:
            info += f'\n\t\tâ¬† {toolbox.FileSizeConvert.parse_2_file_size(increase_info.get("uploaded"))}'
        if increase_info.get("downloaded") > 0:
            info += f'\n\t\tâ¬‡ {toolbox.FileSizeConvert.parse_2_file_size(increase_info.get("downloaded"))}'
        increase_list.append(info)
    incremental = f'â¬† æ€»ä¸Šä¼ ï¼š{toolbox.FileSizeConvert.parse_2_file_size(total_upload)}\n' \
                  f'â¬‡ æ€»ä¸‹è½½ï¼š{toolbox.FileSizeConvert.parse_2_file_size(total_download)}\n' \
                  f'âœ” è¯´æ˜: æ•°æ®å‡ç›¸è¾ƒäºæœ¬ç«™ä»Šæ—¥ä¹‹å‰æœ€è¿‘çš„ä¸€æ¡æ•°æ®ï¼Œå¯èƒ½å¹¶éæ˜¨æ—¥\n' \
                  f'âš› æ•°æ®åˆ—è¡¨ï¼š{"".join(increase_list)}'
    logger.info(incremental)
    toolbox.send_text(title='é€šçŸ¥ï¼šä»Šæ—¥æ•°æ®', message=incremental)
    end = time.time()
    consuming = f'è‡ªåŠ¨æ›´æ–°ä¸ªäººæ•°æ® ä»»åŠ¡è¿è¡ŒæˆåŠŸï¼å…±æœ‰{len(queryset)}ä¸ªç«™ç‚¹éœ€è¦æ‰§è¡Œï¼Œ' \
                f'å…±è®¡æˆåŠŸ {len(success_message)} ä¸ªç«™ç‚¹ï¼Œå¤±è´¥ {len(failed_message)} ä¸ªç«™ç‚¹ï¼Œ' \
                f'è€—æ—¶ï¼š{round(end - start, 2)} å®Œæˆæ—¶é—´ï¼š{time.strftime("%Y-%m-%d %H:%M:%S")}  \n'
    message_list.append(consuming)
    logger.info(message_list)
    message_list.extend(failed_message)
    message_list.append('*' * 20)
    message_list.extend(success_message)
    toolbox.send_text(title='é€šçŸ¥ï¼šæ›´æ–°ä¸ªäººæ•°æ®', message='\n'.join(message_list))
    # toolbox.send_text(title='é€šçŸ¥ï¼šæ›´æ–°ä¸ªäººæ•°æ®-æˆåŠŸ', message='\n'.join(success_message))
    # é‡Šæ”¾å†…å­˜
    gc.collect()
    return message_list


@shared_task(bind=True, base=BaseTask, autoretry_for=(Exception,), )
def auto_get_torrents(self, *site_list: List[int]):
    """
    æ‹‰å–æœ€æ–°ç§å­
    """
    start = time.time()
    message_list = []
    message_success = ['### è¿™äº›æˆåŠŸäº†  \n']
    message_failed = ['### è¿™äº›å‡ºé”™äº†  \n']
    message_push = ['### è¿™æ˜¯æ¨åˆ°ä¸‹è½½å™¨çš„  \n']
    websites = WebSite.objects.all()
    queryset = [my_site for my_site in MySite.objects.filter(id__in=site_list) if
                websites.get(id=my_site.site).brush_free]
    results = pool.map(pt_spider.send_torrent_info_request, queryset)
    for my_site, result in zip(queryset, results):
        logger.debug('è·å–ç§å­ï¼š{}{}'.format(my_site.nickname, result))
        # print(result is tuple[int])
        if result.code == 0:
            res = pt_spider.get_torrent_info_list(my_site, result.data)
            # é€šçŸ¥æ¨é€
            if res.code == 0:
                message = f'> âœ… {my_site.nickname}ç§å­æŠ“å–æˆåŠŸï¼ {res.msg}  \n\n'
                logger.debug(message)
                message_success.append(message)
                site = websites.get(id=my_site.site)
                logging.info(f'ç«™ç‚¹Freeåˆ·æµï¼š{my_site.brush_free}ï¼Œç»‘å®šä¸‹è½½å™¨ï¼š{my_site.downloader}')
                if my_site.downloader:
                    torrents = res.data
                    if len(res.data) <= 0:
                        continue
                    # è§£æåˆ·æµæ¨é€è§„åˆ™,ç­›é€‰ç¬¦åˆæ¡ä»¶çš„ç§å­å¹¶æ¨é€åˆ°ä¸‹è½½å™¨
                    torrents = toolbox.filter_torrent_by_rules(my_site, torrents)
                    msg = f'> âœ… {my_site.nickname} ç«™ç‚¹å…±æœ‰{len(res.data)}æ¡ç§å­æœªæ¨é€,æœ‰ç¬¦åˆæ¡ä»¶çš„ç§å­ï¼š{len(torrents)} ä¸ªï¼  \n\n'
                    logger.debug(msg)
                    client, downloader_category = toolbox.get_downloader_instance(my_site.downloader_id)
                    for torrent in torrents:
                        # é™é€Ÿåˆ°ç«™ç‚¹é™é€Ÿçš„92%ã€‚ä»¥é˜²è¶…é€Ÿ
                        category = f'{site.nickname}-{torrent.tid}' if not torrent.hash_string else site.nickname
                        toolbox.push_torrents_to_downloader(
                            client, downloader_category,
                            urls=torrent.magnet_url,
                            cookie=my_site.cookie,
                            category=category,
                            upload_limit=int(site.limit_speed * 1024 * 0.92)
                        )
                        torrent.downloader = my_site.downloader
                        torrent.state = 1
                        torrent.save()
                    message_push.append(msg)
            else:
                message = f'> ğŸ†˜ {my_site.nickname} æŠ“å–ç§å­ä¿¡æ¯å¤±è´¥ï¼åŸå› ï¼š{res.msg}  \n'
                message_failed.append(message)
                logger.error(message)
        else:
            # toolbox.send_text(my_site.nickname + ' æŠ“å–ç§å­ä¿¡æ¯å¤±è´¥ï¼åŸå› ï¼š' + result[0])
            message = f'> ğŸ†˜ {my_site.nickname} æŠ“å–ç§å­ä¿¡æ¯å¤±è´¥ï¼åŸå› ï¼š{result.msg}  \n'
            logger.error(message)
            message_failed.append(message)
    end = time.time()
    consuming = f'> â™»ï¸ æ‹‰å–æœ€æ–°ç§å­ ä»»åŠ¡è¿è¡ŒæˆåŠŸï¼å…±æœ‰{len(site_list)}ä¸ªç«™ç‚¹éœ€è¦æ‰§è¡Œï¼Œæ‰§è¡ŒæˆåŠŸ{len(message_success) - 1}ä¸ªï¼Œ' \
                f'å¤±è´¥{len(message_failed) - 1}ä¸ªã€‚æœ¬æ¬¡ä»»åŠ¡è€—æ—¶ï¼š{end - start} å½“å‰æ—¶é—´ï¼š{time.strftime("%Y-%m-%d %H:%M:%S")}  \n\n'
    message_list.append(consuming)
    if len(message_failed) > 1:
        message_list.extend(message_failed)
    message_list.extend(message_success)
    if len(message_push) > 1:
        message_list.extend(message_push)
    logger.info(consuming)
    # toolbox.send_text(title='é€šçŸ¥ï¼šæ‹‰å–æœ€æ–°ç§å­', message='\n'.join(message_list))
    # if len(message_success) > 0:
    #     toolbox.send_text(title='é€šçŸ¥ï¼šæ‹‰å–æœ€æ–°ç§å­-æˆåŠŸ', message=''.join(message_success))
    # é‡Šæ”¾å†…å­˜
    gc.collect()
    return consuming


# @shared_task(bind=True, base=BaseTask)
# def auto_get_hash_by_category(self, ):
#     start = time.time()
#     my_site_list = MySite.objects.filter(brush_free=True, downloader__isnull=False).all()
#     results = pool.map(toolbox.get_hash_by_category, my_site_list)
#     failed_msg = []
#     succeeded_msg = []
#     for result in results:
#         succeeded_msg.append(result.msg) if result.code == 0 else failed_msg.append(result.msg)
#     end = time.time()
#     consuming = f'> â™»ï¸ å®Œå–„ç§å­ä¿¡æ¯ ä»»åŠ¡è¿è¡ŒæˆåŠŸï¼æ‰§è¡ŒæˆåŠŸ{len(succeeded_msg)}ä¸ªï¼Œå¤±è´¥{len(failed_msg)}ä¸ªã€‚' \
#                 f'æœ¬æ¬¡ä»»åŠ¡è€—æ—¶ï¼š{end - start} å½“å‰æ—¶é—´ï¼š{time.strftime("%Y-%m-%d %H:%M:%S")}  \n'
#     logger.info(consuming)
#     message_list = [consuming]
#     message_list.extend(failed_msg)
#     message_list.extend(succeeded_msg)
#     toolbox.send_text(title='é€šçŸ¥ï¼šå®Œå–„ç§å­ä¿¡æ¯', message='\n'.join(message_list))
#     # if len(succeeded_msg) > 0:
#     #     toolbox.send_text(title='é€šçŸ¥ï¼šå®Œå–„ç§å­ä¿¡æ¯-æˆåŠŸ', message='\n'.join(succeeded_msg))
#     # é‡Šæ”¾å†…å­˜
#     gc.collect()
#     return '\n'.join(message_list)


# @shared_task(bind=True, base=BaseTask)
# def auto_calc_torrent_pieces_hash(self, ):
#     """
#     è®¡ç®—ç§å­å—HASH(æ ¹æ®ç§å­ä¿¡æ¯è¿›è¡Œè¡¥å…¨)
#     """
#     start = time.time()
#     torrent_info_list = TorrentInfo.objects.filter(
#         downloader__isnull=False, state=1, pieces_qb__isnull=True
#     ).all()
#     website_list = WebSite.objects.all()
#     count = 0
#     for torrent_info in torrent_info_list:
#         logger.info('ç§å­åç§°ï¼š{}'.format(torrent_info.title))
#         try:
#             client, _ = toolbox.get_downloader_instance(torrent_info.downloader_id)
#             if not torrent_info.hash_string:
#                 # ç§å­ä¿¡æ¯æœªå¡«å†™hashçš„ï¼Œç»„è£…åˆ†ç±»ä¿¡æ¯ï¼Œåˆ°ä¸‹è½½å™¨æŸ¥è¯¢ç§å­ä¿¡æ¯
#                 site = website_list.get(id=torrent_info.site.site)
#                 category = f'{site.nickname}-{torrent_info.tid}'
#                 torrents = client.torrents_info(category=category)
#             else:
#                 # ä»¥åhashçš„ç›´æ¥æŸ¥è¯¢
#                 torrents = client.torrents_info(torrent_hashes=torrent_info.hash_string)
#             if len(torrents) == 1:
#                 # ä¿å­˜ç§å­hash
#                 hash_string = torrents[0].hash_string
#                 torrent_info.hash_string = hash_string
#                 # è·å–ç§å­å—HASHåˆ—è¡¨ï¼Œå¹¶ç”Ÿæˆç§å­å—HASHåˆ—è¡¨å­—ç¬¦ä¸²çš„sha1å€¼ï¼Œä¿å­˜
#                 pieces_hash_list = client.torrents_piece_hashes(torrent_hash=hash_string)
#                 pieces_hash_string = str(pieces_hash_list).replace(' ', '')
#                 torrent_info.pieces_hash = hashlib.sha1(pieces_hash_string.encode()).hexdigest()
#                 # è·å–æ–‡ä»¶åˆ—è¡¨ï¼Œå¹¶ç”Ÿæˆæ–‡ä»¶åˆ—è¡¨å­—ç¬¦ä¸²çš„sha1å€¼ï¼Œä¿å­˜
#                 file_list = client.torrents_files(torrent_hash=hash_string)
#                 file_list_hash_string = str(file_list).replace(' ', '')
#                 torrent_info.filelist = hashlib.sha1(file_list_hash_string.encode()).hexdigest()
#                 torrent_info.files_count = len(file_list)
#             torrent_info.state = 1
#             torrent_info.save()
#             count += 1
#         except Exception as e:
#             logging.error(traceback.format_exc(3))
#             continue
#     end = time.time()
#     message = f'> è®¡ç®—ç§å­Piecesçš„HASHå€¼ ä»»åŠ¡è¿è¡ŒæˆåŠŸï¼å…±æˆåŠŸå¤„ç†ç§å­{count}ä¸ªï¼Œè€—æ—¶ï¼š{end - start}  \n{time.strftime("%Y-%m-%d %H:%M:%S")}'
#     toolbox.send_text(title='é€šçŸ¥ï¼šè®¡ç®—ç§å­HASH', message=message)
#     # é‡Šæ”¾å†…å­˜
#     gc.collect()


@shared_task(bind=True, base=BaseTask)
def auto_get_rss(self, *site_list: List[int]):
    start = time.time()
    # site_list = site_list.split('|')
    logger.info(site_list)
    my_site_list = MySite.objects.filter(id__in=site_list, rss__startswith='https://').all()
    websites = WebSite.objects.filter(brush_rss=True).all()
    message_list = []
    message_failed = []
    message_success = []
    results = pool.map(toolbox.parse_rss, [my_site.rss for my_site in my_site_list])
    for my_site, result in zip(my_site_list, results):
        try:
            website = websites.get(id=my_site.site)
            updated = 0
            created = 0
            torrent_list = []
            # urls = []
            for t in result:
                tid = t.get('tid')
                # ç»„è£…ç§å­è¯¦æƒ…é¡µURL è§£æè¯¦æƒ…é¡µä¿¡æ¯
                # res_detail = pt_spider.get_torrent_detail(my_site, f'{website.url}{website.page_detail.format(tid)}')
                # å¦‚æœæ— æŠ¥é”™ï¼Œå°†ä¿¡æ¯åˆå¹¶åˆ°torrent
                # if res_detail.code == 0:
                #     torrent.update(res_detail.data)
                logger.debug(t)
                res = TorrentInfo.objects.update_or_create(site=my_site, tid=tid, defaults=t, )
                if res[1]:
                    res[0].downloader = my_site.downloader
                    res[0].save()
                    torrent_list.append(res[0])
                    created += 1
                else:
                    updated += 1
                # logger.debug(res)
            msg = f'âœ… {my_site.nickname} æ–°å¢ç§å­ï¼š{created} ä¸ªï¼Œæ›´æ–°ç§å­ï¼š{updated}ä¸ªï¼'
            logger.info(msg)
            message_success.append(msg)
            logging.info(f'âœ… ç«™ç‚¹RSSåˆ·æµï¼š{my_site.brush_rss}ï¼Œç»‘å®šä¸‹è½½å™¨ï¼š{my_site.downloader}')
            if my_site.brush_rss and my_site.downloader:
                downloader = my_site.downloader
                client, downloader_category = toolbox.get_downloader_instance(downloader.id)
                push_message = []
                for torrent in torrent_list:
                    torrent.magnet_url = f'{website.url}{website.page_download.format(torrent.tid)}'
                    res = toolbox.push_torrents_to_downloader(
                        client, downloader_category,
                        urls=torrent.magnet_url,
                        cookie=my_site.cookie,
                        is_paused=my_site.package_file and downloader.package_files,
                        category=f'{website.nickname}-{torrent.tid}'
                    )
                    if res.code == 0:
                        torrent.downloader = downloader
                        torrent.state = 1
                        torrent.save()
                    msg = f'{torrent.title} æ¨é€çŠ¶æ€ï¼š{res.msg}'
                    logging.info(msg)
                    push_message.append(msg)
                message = f'> â™»ï¸ RSS ä»»åŠ¡è¿è¡ŒæˆåŠŸï¼è€—æ—¶ï¼š{time.time() - start}  \n' \
                          f'å½“å‰æ—¶é—´ï¼š{time.strftime("%Y-%m-%d %H:%M:%S")} \n ç§å­æ¨é€è®°å½•' + '\n'.join(push_message)
                logging.info(f'â„¹ï¸ ç«™ç‚¹æ‹†åŒ…çŠ¶æ€ï¼š{my_site.package_file}ï¼Œä¸‹è½½å™¨æ‹†åŒ…çŠ¶æ€ï¼š{downloader.package_files}')
                # æ‹†åŒ…
                if my_site.package_file and downloader.package_files:
                    package_start = time.time()
                    # 30ç§’ç­‰å¾…ç§å­ä¸‹è½½åˆ°ä¸‹è½½å™¨
                    time.sleep(30)
                    hash_list = []
                    for hash_string in [torrent.hash for torrent in torrent_list]:
                        try:
                            toolbox.package_files(
                                client=client, hash_string=hash_string,
                                package_size=downloader.package_size,
                                package_percent=downloader.package_percent,
                                delete_one_file=downloader.delete_one_file,
                            )
                        except Exception as e:
                            logger.error(traceback.format_exc(3))
                            # æ‹†åŒ…å¤±è´¥çš„å†™å…¥hash_list
                            hash_list.append(hash_string)
                            continue
                    message = f'â™»ï¸ æ‹†åŒ…ä»»åŠ¡æ‰§è¡Œç»“æŸï¼è€—æ—¶ï¼š{time.time() - package_start} \n ' \
                              f'å½“å‰æ—¶é—´ï¼š{time.strftime("%Y-%m-%d %H:%M:%S")} \n' \
                              f'æˆåŠŸæ‹†åŒ…{len(torrent_list) - len(hash_list)}ä¸ªï¼Œå¤±è´¥{len(hash_list)}ä¸ªï¼'
                    toolbox.send_text(title='æ‹†åŒ…', message=message)
                    package_files = {
                        'site': my_site.nickname,
                        'time': time.strftime("%Y-%m-%d %H:%M:%S"),
                        'downloader_id': downloader.id,
                        'hash_list': hash_list
                    }
                    # ä»ç¼“å­˜è·å–éœ€è¦æ‹†åŒ…çš„ä»»åŠ¡å‚æ•°åˆ—è¡¨
                    cache_package_files_list = cache.get(f'cache_package_files_list')
                    if not cache_package_files_list or len(cache_package_files_list) <= 0:
                        cache_package_files_list = [package_files]
                    else:
                        # å¦‚æœåˆ—è¡¨å­˜åœ¨å°±è®²æœ¬æ¬¡ç”Ÿæˆçš„å‚æ•°æ·»åŠ åˆ°åˆ—è¡¨æœ«å°¾
                        cache_package_files_list.append(package_files)
                    # æ›´æ–°å‚æ•°åˆ—è¡¨
                    cache.set(f'cache_package_files_list', cache_package_files_list, 60 * 60 * 24)
        except Exception as e:
            logger.error(traceback.format_exc(3))
            msg = f'{my_site.nickname} RSSè·å–æˆ–è§£æå¤±è´¥'
            logger.error(msg)
            message_failed.append(msg)
            continue
    end = time.time()
    message = f'> â™»ï¸ RSS ä»»åŠ¡è¿è¡ŒæˆåŠŸï¼è€—æ—¶ï¼š{end - start}  \n{time.strftime("%Y-%m-%d %H:%M:%S")} \n'
    message_list.append(message)
    message_list.extend(message_failed)
    message_list.extend(message_success)
    msg = '\n - '.join(message_list)
    # toolbox.send_text(title='é€šçŸ¥ï¼šRSS ä»»åŠ¡è¿è¡ŒæˆåŠŸï¼', message=msg)
    return msg


@shared_task(bind=True, base=BaseTask)
def auto_torrents_package_files(self):
    """
    æ‹†åŒ…å¹¶ä¸‹è½½
    :param self:
    :return:
    """
    cache_package_files_list = cache.get(f'cache_package_files_list')
    if not cache_package_files_list or len(cache_package_files_list) <= 0:
        logger.info('â æ²¡æœ‰ä»»åŠ¡ï¼Œæˆ‘å»ç©è€äº†ï¼Œä¸€ä¼šå„¿å†æ¥ï¼')
        pass
    else:
        message_list = []
        for index, package in enumerate(cache_package_files_list):
            try:
                downloader_id = package.get("downloader_id")
                client, _ = toolbox.get_downloader_instance(downloader_id)
                downloader = Downloader.objects.get(id=downloader_id)
                # æ‹†åŒ…
                hash_list = package.get("hash_list")
                packaged_hashes = []
                succeed = 0
                for hash_string in hash_list:
                    try:
                        toolbox.package_files(
                            client=client, hash_string=hash_string,
                            package_size=downloader.package_size,
                            package_percent=downloader.package_percent,
                            delete_one_file=downloader.delete_one_file,
                        )
                        packaged_hashes.append(hash_string)
                        succeed += 1
                    except Exception as e:
                        logger.error(traceback.format_exc(3))
                # å¼€å§‹ä¸‹è½½
                if len(packaged_hashes) == len(hash_list):
                    # æ‹†åŒ…å®Œæˆçš„ä»»åŠ¡ä»åˆ—è¡¨ä¸­ç§»é™¤
                    del cache_package_files_list[index]
                    msg = f"âœ… {package.get('site')} {package.get('time')}å†™å…¥çš„æ‹†åŒ…ä»»åŠ¡æ‰§è¡Œç»“æŸï¼Œå¼€å§‹ä¸‹è½½"
                    logger.info(msg)
                else:
                    msg = f"ğŸ†˜ {package.get('site')} {package.get('time')}æ‹†åŒ…ç»“æŸï¼Œéƒ¨åˆ†ç§å­æ“ä½œå¤±è´¥ï¼Œä¸‹æ¬¡é‡è¯•ï¼Œç°åœ¨å¼€å§‹ä¸‹è½½å·²æ‹†åŒ…ç§å­"
                    logger.info(msg)
                # torrents = client.torrents_info(status_filter='paused')
                # if len(torrents) > 0:
                #     for torrent in torrents:
                #         try:
                #             toolbox.package_files(client=client, hash_string=torrent.get('hash'))
                #         except Exception as e:
                #             logger.error(e)
                #             continue
                client.torrents_resume(torrent_hashes=packaged_hashes)
                msg = f"\n âœ… {package.get('site')} {package.get('time')}æ¨é€çš„ç§å­æ‹†åŒ…å®Œæˆï¼Œ" \
                      f"æˆåŠŸæ‹†åŒ…{succeed}ä¸ªï¼Œå¤±è´¥{len(hash_list) - succeed}ä¸ªï¼Œå¼€å§‹ä¸‹è½½"
                logger.info(msg)
                message_list.append(msg)
            except Exception as e:
                logger.error(traceback.format_exc(3))
                continue
        message = f'â™»ï¸ æ‹†åŒ…ä»»åŠ¡æ‰§è¡Œç»“æŸï¼{time.strftime("%Y-%m-%d %H:%M:%S")} \n {"".join(message_list)}'
        toolbox.send_text(title='æ‹†åŒ…', message=message)


@shared_task(bind=True, base=BaseTask)
def auto_cleanup_not_registered(self):
    downloaders = Downloader.objects.filter(category=DownloaderCategory.qBittorrent, brush=True)
    not_registered_msg = [
        'torrent not registered with this tracker',
        'err torrent deleted due to other',
    ]
    for downloader in downloaders:
        hashes = []
        client, _ = toolbox.get_downloader_instance(downloader.id)
        torrents = client.torrents_info(status_filter='stalled_downloading|stalledUP')
        for torrent in torrents:
            hash_string = torrent.get('hash')
            trackers = client.torrents_trackers(torrent_hash=hash_string)
            tracker_checked = False
            tracker_msg_list = [tracker.get('msg').lower() for tracker in trackers]
            for tracker_msg in tracker_msg_list:
                delete_msg = [msg for msg in not_registered_msg if tracker_msg.startswith(msg)]
                msg = f'{torrent.get("name")} - {hash_string} - msgï¼š{tracker_msg} -{len(delete_msg)}'
                logger.debug(msg)
                if len(delete_msg) > 0:
                    hashes.append(hash_string)
                    # hashes.append(f'{torrent.get("name")} - {hash_string}')
                    tracker_checked = True
                    break
            if tracker_checked:
                continue
        logger.info(f'âœ… {downloader.name} æœ¬æ¬¡ä»»åŠ¡å…±æ£€æŸ¥å‡º {len(hashes)} ä¸ªå·²åˆ é™¤ç§å­ï¼')
        if len(hashes) > 0:
            toolbox.send_text(title='å·²å¤±æ•ˆç§å­', message='â™»ï¸ {}\n{}'.format(downloader.name, '\n'.join(hashes)))
            # todo æœªæ¥åœ¨è¿™é‡Œä¼šå°†å·²è¢«åˆ é™¤çš„ç§å­HASHå‘é€è‡³æœåŠ¡å™¨
            client.torrents_delete(torrent_hashes=hashes, delete_files=True)


@shared_task(bind=True, base=BaseTask)
def auto_remove_brush_task(self, *site_list: List[int]):
    my_site_list = MySite.objects.filter(
        Q(brush_rss=True) | Q(brush_free=True), downloader__isnull=False, id__in=site_list,
        remove_torrent_rules__startswith='{', ).all()
    message_list = []
    websites = WebSite.objects.filter(brush_rss=True, id__in=[my_site.site for my_site in my_site_list]).all()
    results = pool.map(toolbox.remove_torrent_by_site_rules, my_site_list)
    for res in results:
        if res.code == 0:
            message_list.append(res.msg)
        else:
            message_list.insert(0, res.msg)
    message = '\n\n> '.join(message_list)
    logger.debug(message)
    if len(message_list) > 0:
        toolbox.send_text(title='åˆ·æµåˆ ç§', message=message)
    return message


@shared_task(bind=True, base=BaseTask)
def auto_get_rss_torrent_detail(self, my_site_id: int = None):
    if not my_site_id:
        my_site_list = MySite.objects.filter(brush_free=True, rss__contains='http').all()
    else:
        my_site_list = MySite.objects.filter(id=my_site_id, brush_free=True, rss__contains='http').all()
    if len(my_site_list) <= 0:
        return 'â æ²¡æœ‰ç«™ç‚¹éœ€è¦RSSï¼Œè¯·æ£€æŸ¥RSSé“¾æ¥ä¸æŠ“ç§å¼€å…³ï¼'
    website_list = WebSite.objects.all()
    results = pool.map(toolbox.parse_rss, [my_site.rss for my_site in my_site_list])
    for my_site, result in zip(my_site_list, results):
        try:
            website = website_list.get(id=my_site.site)
            hash_list = []
            urls = []
            updated = 0
            created = 0
            for torrent in result:
                tid = torrent.get('tid')
                urls.append(f'{website.url}{website.page_download.format(tid)}')
                # ç»„è£…ç§å­è¯¦æƒ…é¡µURL è§£æè¯¦æƒ…é¡µä¿¡æ¯
                # res_detail = pt_spider.get_torrent_detail(my_site, f'{website.url}{website.page_detail.format(tid)}')
                # å¦‚æœæ— æŠ¥é”™ï¼Œå°†ä¿¡æ¯åˆå¹¶åˆ°torrent
                # if res_detail.code == 0:
                #     torrent.update(res_detail.data)
                res = TorrentInfo.objects.update_or_create(
                    site=my_site,
                    tid=tid,
                    defaults=torrent,
                )
                if res[1]:
                    created += 1
                else:
                    updated += 1
                logger.info(res)
                hash_list.append(res[0].hash_string)
            if website.brush_rss and my_site.brush_rss and my_site.downloader:
                downloader = my_site.downloader
                client, downloader_category = toolbox.get_downloader_instance(downloader.id)
                res = toolbox.push_torrents_to_downloader(
                    client, downloader_category,
                    urls=urls,
                    cookie=my_site.cookie,
                )
                if downloader.package_files:
                    client, _ = toolbox.get_downloader_instance(downloader.id)
                    for hash_string in hash_list:
                        toolbox.package_files(
                            client=client,
                            hash_string=hash_string
                        )
                logging.info(res.msg)
            msg = f'âœ… {my_site.nickname} æ–°å¢ç§å­{created} ä¸ªï¼Œæ›´æ–°{updated}ä¸ª'
            logger.info(msg)
            toolbox.send_text(title='RSS', message=msg)
            if len(my_site_list) == 1:
                return {'hash_list': hash_list, 'msg': msg}
        except Exception as e:
            msg = f'âŒ {my_site.nickname} RSSè·å–æˆ–è§£æå¤±è´¥'
            logger.error(msg)
            logger.error(traceback.format_exc(3))
            if len(my_site_list) == 1:
                return msg
            continue


@shared_task(bind=True, base=BaseTask)
def auto_get_update_torrent(self, torrent_id):
    if isinstance(torrent_id, str):
        torrent_ids = torrent_id.split('|')
        torrent_list = TorrentInfo.objects.filter(id__in=torrent_ids).all()
    else:
        torrent_list = TorrentInfo.objects.filter(state=False).all()
    count = 0
    for torrent in torrent_list:
        try:
            res = pt_spider.get_update_torrent(torrent)
            if res.code == 0:
                count += 1
        except Exception as e:
            logger.error(traceback.format_exc(3))
            continue
    msg = f'â™»ï¸ å…±æœ‰{len(torrent_list)}ç§å­éœ€è¦æ›´æ–°ï¼Œæœ¬æ¬¡æ›´æ–°æˆåŠŸ{count}ä¸ªï¼Œå¤±è´¥{len(torrent_list) - count}ä¸ª'
    logger.info(msg)


@shared_task(bind=True, base=BaseTask)
def auto_push_to_downloader(self, *site_list: List[int]):
    """æ¨é€åˆ°ä¸‹è½½å™¨"""
    start = time.time()
    logging.info('â„¹ï¸ æ¨é€ç§å­åˆ°ä¸‹è½½å™¨ä»»åŠ¡å¼€å§‹')
    my_site_list = MySite.objects.filter(brush_free=True, id__in=site_list).all()
    website_list = WebSite.objects.all()
    message_list = []
    for my_site in my_site_list:
        site = website_list.get(id=my_site.site)
        logging.info(f'â„¹ï¸ ç«™ç‚¹Freeåˆ·æµï¼š{my_site.brush_free}ï¼Œç»‘å®šä¸‹è½½å™¨ï¼š{my_site.downloader}')
        torrents = TorrentInfo.objects.filter(site=my_site, state=0, sale_status__contains='Free')
        logger.info(f'â„¹ï¸ ç«™ç‚¹æœ‰{len(torrents)}æ¡ç§å­æœªæ¨é€')
        if my_site.downloader:
            # è§£æåˆ·æµæ¨é€è§„åˆ™,ç­›é€‰ç¬¦åˆæ¡ä»¶çš„ç§å­å¹¶æ¨é€åˆ°ä¸‹è½½å™¨
            torrents = toolbox.filter_torrent_by_rules(my_site, torrents)
            logger.info(f'â„¹ï¸ å…±æœ‰ç¬¦åˆæ¡ä»¶çš„ç§å­ï¼š{len(torrents)} ä¸ª')
            client, downloader_category = toolbox.get_downloader_instance(my_site.downloader_id)
            for torrent in torrents:
                # é™é€Ÿåˆ°ç«™ç‚¹é™é€Ÿçš„92%ã€‚ä»¥é˜²è¶…é€Ÿ
                toolbox.push_torrents_to_downloader(
                    client, downloader_category,
                    urls=torrent.magnet_url,
                    cookie=my_site.cookie,
                    category=f'{site.nickname}-{torrent.tid}',
                    upload_limit=int(site.limit_speed * 1024 * 0.92)
                )
                torrent.downloader = my_site.downloader
                torrent.state = 1
                torrent.save()
            msg = f'âœ… {my_site.nickname} ç«™ç‚¹å…±æœ‰{len(torrents)}æ¡ç§å­æœªæ¨é€,æœ‰ç¬¦åˆæ¡ä»¶çš„ç§å­ï¼š{len(torrents)} ä¸ª'
            message_list.append('\n')
            message_list.append(msg)
    end = time.time()
    message = f'> â™»ï¸ ç­¾åˆ° ä»»åŠ¡è¿è¡ŒæˆåŠŸï¼è€—æ—¶ï¼š{end - start}  \n{time.strftime("%Y-%m-%d %H:%M:%S")} \n{"".join(message_list)}'
    toolbox.send_text(title='é€šçŸ¥ï¼šæ¨é€ç§å­ä»»åŠ¡', message=message)
    # é‡Šæ”¾å†…å­˜
    gc.collect()


@shared_task(bind=True, base=BaseTask)
def auto_update_torrent_info(self, ):
    """è‡ªåŠ¨è·å–ç§å­"""
    start = time.time()
    print('è‡ªåŠ¨è·å–ç§å­HASH')
    time.sleep(5)
    end = time.time()
    message = f'> â™»ï¸è·å–ç§å­HASH ä»»åŠ¡è¿è¡ŒæˆåŠŸï¼è€—æ—¶ï¼š{end - start}  \n{time.strftime("%Y-%m-%d %H:%M:%S")}'
    toolbox.send_text(title='é€šçŸ¥ï¼šè‡ªåŠ¨è·å–ç§å­HASH', message=message)
    # é‡Šæ”¾å†…å­˜
    gc.collect()


@shared_task(bind=True, base=BaseTask)
def exec_command(self, commands):
    """æ‰§è¡Œå‘½ä»¤è¡Œå‘½ä»¤"""
    result = []
    for key, command in commands.items():
        p = subprocess.run(command, shell=True)
        logger.info('{} å‘½ä»¤æ‰§è¡Œç»“æœï¼š\n{}'.format(key, p))
        result.append({
            'command': key,
            'res': p.returncode
        })
    # é‡Šæ”¾å†…å­˜
    gc.collect()
    return result


@shared_task(bind=True, base=BaseTask)
def auto_program_upgrade(self, ):
    """ç¨‹åºæ›´æ–°"""
    try:
        logger.info('å¼€å§‹è‡ªåŠ¨æ›´æ–°')
        update_commands = {
            # 'cp db/db.sqlite3 db/db.sqlite3-$(date "+%Y%m%d%H%M%S")',
            'æ›´æ–°ä¾èµ–ç¯å¢ƒ': 'wget -O requirements.txt https://gitee.com/ngfchl/ptools/raw/master/requirements.txt &&'
                            ' pip install -r requirements.txt -U',
            'å¼ºåˆ¶è¦†ç›–æœ¬åœ°': 'git clean -df && git reset --hard',
            'è·å–æ›´æ–°ä¿¡æ¯': 'git fetch --all',
            'æ‹‰å–ä»£ç æ›´æ–°': f'git pull origin {os.getenv("DEV")}',
        }
        logger.info('æ‹‰å–æœ€æ–°ä»£ç ')
        result = exec_command(update_commands)
        logger.info('æ›´æ–°å®Œæ¯•')
        message = f'> æ›´æ–°å®Œæˆï¼ï¼è¯·åœ¨æ¥åˆ°é€šçŸ¥ååŒæ­¥æ•°æ®åº“ï¼{datetime.now()}'
        toolbox.send_text(title='é€šçŸ¥ï¼šç¨‹åºæ›´æ–°', message=message)
        return CommonResponse.success(
            msg='æ›´æ–°æˆåŠŸï¼ç¨åè¯·åœ¨æ¥åˆ°é€šçŸ¥ååŒæ­¥æ•°æ®åº“ï¼ï¼',
            data={
                'result': result
            }
        )
    except Exception as e:
        # raise
        msg = 'æ›´æ–°å¤±è´¥!{}ï¼Œè¯·å°è¯•åŒæ­¥æ•°æ®åº“ï¼'.format(str(e))
        logger.error(msg)
        message = f'> <font color="red">{msg}</font>'
        toolbox.send_text(title=msg, message=message)
        return CommonResponse.error(
            msg=msg
        )
    finally:
        # é‡Šæ”¾å†…å­˜
        gc.collect()


@shared_task(bind=True, base=BaseTask)
def auto_remove_expire_torrent(self):
    """
    æ¸…ç†å…è´¹åˆ°æœŸçš„ç§å­
    :param self:
    :return:
    """
    # ç­›é€‰æ ‡è®°ä¸ºåˆ·æµçš„ä¸‹è½½å™¨
    downloaders = Downloader.objects.filter(brush=True).all()
    # ç­›é€‰å·²æ¨é€åˆ°ä¸‹è½½å™¨çš„ç§å­
    torrent_info_list = TorrentInfo.objects.filter(state=1, downloader__in=downloaders).all()
    for downloader in downloaders:
        client, _ = toolbox.get_downloader_instance(downloader.id)
        # ç­›é€‰å·²è¿‡æœŸå’Œå‰©ä½™å…è´¹æ—¶é—´å°äºä¸‰åˆ†é’Ÿçš„ç§å­
        torrents = [torrent for torrent in torrent_info_list if
                    torrent.downloader.id == downloader.id and time.strptime(
                        torrent.sale_expire).timestamp() < time.time() - 60 * 3]
        hashes = [torrent.hash for torrent in torrents]
        # å¦‚æœå¼€å¯äº†ä¿ç•™å·²ä¸‹è½½å®Œæ¯•ç§å­é€‰é¡¹ï¼Œåˆ™é€‰ä¸‹è½½ä¸­çš„ç§å­
        if downloader.keep_completed:
            downloading_torrents = client.torrents_info(
                status_filter=['downloading', 'stalled_downloading'], torrent_hashes=hashes)
            print(downloading_torrents)
            hashes = [torrent.get('hash') for torrent in downloading_torrents]
        client.torrents_delete(torrent_hashes=hashes, delete_files=True)


@shared_task(bind=True, base=BaseTask)
def auto_update_license(self, ):
    """auto_update_license"""
    res = toolbox.generate_config_file()
    if res.code != 0:
        return CommonResponse.error(
            msg=res.msg
        )
    data = toml.load('db/ptools.toml')
    print(data)
    pt_helper = data.get('pt_helper')
    if len(pt_helper) <= 0:
        return CommonResponse.error(
            msg='è¯·å…ˆé…ç½®å°åŠ©æ‰‹ç›¸å…³ä¿¡æ¯å†è¿›è¡Œæ“ä½œï¼'
        )
    host = pt_helper.get('host')
    username = pt_helper.get('username')
    password = pt_helper.get('password')
    url = 'http://get_pt_helper_license.guyubao.com/getTrial'
    license_xpath = '//h2/text()'
    session = requests.Session()
    res = session.get(url=url)
    token = ''.join(etree.HTML(res.content).xpath(license_xpath))
    login_url = host + '/login/submit'
    login_res = session.post(
        url=login_url,
        data={
            'username': username,
            'password': password,
        }
    )
    token_url = host + '/sys/config/update'
    logger.info(login_res.cookies.get_dict())
    cookies = session.cookies.get_dict()
    logger.info(cookies)
    res = session.post(
        url=token_url,
        cookies=cookies,
        data={
            'Id': 4,
            'ParamKey': 'license',
            'ParamValue': token.split('ï¼š')[-1],
            'Status': 1,
        }
    )
    logger.info(f'ç»“æœï¼š{res.text}')
    result = res.json()
    if result.get('code') == 0:
        result['data'] = token
        toolbox.send_text(title='å°åŠ©æ‰‹Licenseæ›´æ–°æˆåŠŸï¼', message=f'> {token}')
        return CommonResponse.success(
            data=result
        )
    # é‡Šæ”¾å†…å­˜
    gc.collect()
    return CommonResponse.error(
        msg=f'Licenseæ›´æ–°å¤±è´¥ï¼'
    )


@shared_task(bind=True, base=BaseTask)
def import_from_ptpp(self, data_list: List):
    results = pool.map(pt_spider.get_uid_and_passkey, data_list)

    message_list = [result.msg for result in results]
    logger.info(message_list)
    # send_text(title='PTPPç«™ç‚¹å¯¼å…¥é€šçŸ¥', message='Cookiesè§£æå¤±è´¥ï¼Œè¯·ç¡®è®¤å¯¼å…¥äº†æ­£ç¡®çš„cookieså¤‡ä»½æ–‡ä»¶ï¼')
    toolbox.send_text(title='PTPPç«™ç‚¹å¯¼å…¥é€šçŸ¥', message='\n\n'.join(message_list))
    return message_list


@shared_task(bind=True, base=BaseTask)
def test_task(self, *args):
    logger.info(args)
    toolbox.send_text(title='æµ‹è¯•', message=str(args))
    return args
